I highly set up a virtual python enviroment because we are in a development phrase which mean<br>
# Dependencies

**Python Libraries**
```
pip install -r requirements.txt
```

**[Llama3.1:8b](https://ollama.com/library/llama3.1:8b)**
```
ollama pull llama3.1:8b
```

**[Embed Model](https://ollama.com/library/nomic-embed-text:v1.5)**
```
ollama pull nomic-embed-text:v1.5
```

**[Rerank model](https://ollama.com/linux6200/bge-reranker-v2-m3/tags)**
```
ollama pull linux6200/bge-reranker-v2-m3
```

# Note
As of 11/08/25, Qwen3-Embedding-0.6B is the number 4 model on the Embedding Leaderboard. The top three models are: <br>
1. gemini-embedding-001 <br>
2. Qwen3-Embedding-8B <br>
3. Qwen3-Embedding-4B" <br>


# Embedding 
Took me 3h9m19s
